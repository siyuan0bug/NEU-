{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:06.750466Z",
     "iopub.status.busy": "2023-12-18T15:13:06.750138Z",
     "iopub.status.idle": "2023-12-18T15:13:06.757818Z",
     "shell.execute_reply": "2023-12-18T15:13:06.757020Z",
     "shell.execute_reply.started": "2023-12-18T15:13:06.750419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet50', 'neu-grading4', 'aptos2019-blindness-detection']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:06.768228Z",
     "iopub.status.busy": "2023-12-18T15:13:06.767890Z",
     "iopub.status.idle": "2023-12-18T15:13:09.724409Z",
     "shell.execute_reply": "2023-12-18T15:13:09.723633Z",
     "shell.execute_reply.started": "2023-12-18T15:13:06.768163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score, accuracy_score\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "WORKERS = 2\n",
    "CHANNEL = 3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 300\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:09.726608Z",
     "iopub.status.busy": "2023-12-18T15:13:09.726370Z",
     "iopub.status.idle": "2023-12-18T15:13:10.069784Z",
     "shell.execute_reply": "2023-12-18T15:13:10.068596Z",
     "shell.execute_reply.started": "2023-12-18T15:13:09.726569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7aef615d1e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/neu-grading4/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/neu-grading4/test.csv')\n",
    "\n",
    "x = df_train['Image']\n",
    "y = df_train['Retinopathy_grade']\n",
    "\n",
    "x, y = shuffle(x, y, random_state=8)\n",
    "y.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:10.072608Z",
     "iopub.status.busy": "2023-12-18T15:13:10.071948Z",
     "iopub.status.idle": "2023-12-18T15:13:10.078879Z",
     "shell.execute_reply": "2023-12-18T15:13:10.077427Z",
     "shell.execute_reply.started": "2023-12-18T15:13:10.072538Z"
    }
   },
   "outputs": [],
   "source": [
    "# def to_multi_label(target):\n",
    "#     multi_label = np.zeros((len(target), NUM_CLASSES))\n",
    "#     for i in range(len(target)):\n",
    "#         j = target[i] + 1\n",
    "#         multi_label[i][:j] = 1\n",
    "#     return np.array(multi_label)\n",
    "# multi_y = to_multi_label(y)\n",
    "# for j in range(5):\n",
    "#     print('original: ', y[j])\n",
    "#     print('multi-label: ', multi_y[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:10.082522Z",
     "iopub.status.busy": "2023-12-18T15:13:10.081732Z",
     "iopub.status.idle": "2023-12-18T15:13:10.185178Z",
     "shell.execute_reply": "2023-12-18T15:13:10.184402Z",
     "shell.execute_reply.started": "2023-12-18T15:13:10.082218Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.legacy import interfaces\n",
    "from keras.optimizers import Optimizer\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class AdamAccumulate_v1(Optimizer):\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., amsgrad=False, accum_iters=20, **kwargs):\n",
    "        super(AdamAccumulate, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.effective_iterations = K.variable(0, dtype='int64', name='effective_iterations')\n",
    "\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.amsgrad = amsgrad\n",
    "        self.accum_iters = K.variable(accum_iters, dtype='int64')\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "\n",
    "        self.updates = [K.update(self.iterations, self.iterations + 1)]\n",
    "\n",
    "        flag = K.equal(self.iterations % self.accum_iters, self.accum_iters - 1)\n",
    "        flag = K.cast(flag, K.floatx())\n",
    "\n",
    "        self.updates.append(K.update(self.effective_iterations,\n",
    "                                     self.effective_iterations + K.cast(flag, 'int64')))\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.effective_iterations,\n",
    "                                                      K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.effective_iterations, K.floatx()) + 1\n",
    "\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        gs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        else:\n",
    "            vhats = [K.zeros(1) for _ in params]\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        for p, g, m, v, vhat, gg in zip(params, grads, ms, vs, vhats, gs):\n",
    "\n",
    "            gg_t = (1 - flag) * (gg + g)\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * (gg + flag * g) / K.cast(self.accum_iters, K.floatx())\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(\n",
    "                (gg + flag * g) / K.cast(self.accum_iters, K.floatx()))\n",
    "\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                p_t = p - flag * lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                p_t = p - flag * lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
    "\n",
    "            self.updates.append((m, flag * m_t + (1 - flag) * m))\n",
    "            self.updates.append((v, flag * v_t + (1 - flag) * v))\n",
    "            self.updates.append((gg, gg_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'epsilon': self.epsilon,\n",
    "                  'amsgrad': self.amsgrad}\n",
    "        base_config = super(AdamAccumulate, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class AdamAccumulate(Optimizer):\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., amsgrad=False, accum_iters=2, **kwargs):\n",
    "        if accum_iters < 1:\n",
    "            raise ValueError('accum_iters must be >= 1')\n",
    "        super(AdamAccumulate, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.amsgrad = amsgrad\n",
    "        self.accum_iters = K.variable(accum_iters, K.dtype(self.iterations))\n",
    "        self.accum_iters_float = K.cast(self.accum_iters, K.floatx())\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "\n",
    "        completed_updates = K.cast(K.tf.floor(self.iterations / self.accum_iters), K.floatx())\n",
    "\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * completed_updates))\n",
    "\n",
    "        t = completed_updates + 1\n",
    "\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        # self.iterations incremented after processing a batch\n",
    "        # batch:              1 2 3 4 5 6 7 8 9\n",
    "        # self.iterations:    0 1 2 3 4 5 6 7 8\n",
    "        # update_switch = 1:        x       x    (if accum_iters=4)\n",
    "        update_switch = K.equal((self.iterations + 1) % self.accum_iters, 0)\n",
    "        update_switch = K.cast(update_switch, K.floatx())\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        gs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        else:\n",
    "            vhats = [K.zeros(1) for _ in params]\n",
    "\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        for p, g, m, v, vhat, tg in zip(params, grads, ms, vs, vhats, gs):\n",
    "\n",
    "            sum_grad = tg + g\n",
    "            avg_grad = sum_grad / self.accum_iters_float\n",
    "\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * avg_grad\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(avg_grad)\n",
    "\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                p_t = p - lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n",
    "                self.updates.append(K.update(vhat, (1 - update_switch) * vhat + update_switch * vhat_t))\n",
    "            else:\n",
    "                p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
    "\n",
    "            self.updates.append(K.update(m, (1 - update_switch) * m + update_switch * m_t))\n",
    "            self.updates.append(K.update(v, (1 - update_switch) * v + update_switch * v_t))\n",
    "            self.updates.append(K.update(tg, (1 - update_switch) * sum_grad))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, (1 - update_switch) * p + update_switch * new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'epsilon': self.epsilon,\n",
    "                  'amsgrad': self.amsgrad}\n",
    "        base_config = super(AdamAccumulate, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:10.188794Z",
     "iopub.status.busy": "2023-12-18T15:13:10.188482Z",
     "iopub.status.idle": "2023-12-18T15:13:10.212127Z",
     "shell.execute_reply": "2023-12-18T15:13:10.211113Z",
     "shell.execute_reply.started": "2023-12-18T15:13:10.188743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850,)\n",
      "(850, 5)\n",
      "(150,)\n",
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n",
    "                                                      stratify=y, random_state=8)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:10.214201Z",
     "iopub.status.busy": "2023-12-18T15:13:10.213770Z",
     "iopub.status.idle": "2023-12-18T15:13:10.223262Z",
     "shell.execute_reply": "2023-12-18T15:13:10.222559Z",
     "shell.execute_reply.started": "2023-12-18T15:13:10.213989Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/aleju/imgaug\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential([\n",
    "    sometimes(\n",
    "        iaa.OneOf([\n",
    "            iaa.Add((-10, 10), per_channel=0.5),\n",
    "            iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "            iaa.ContrastNormalization((0.9, 1.1), per_channel=0.5)\n",
    "        ])\n",
    "    ),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Crop(percent=(0, 0.1)),\n",
    "    iaa.Flipud(0.5)\n",
    "],random_order=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:10.224917Z",
     "iopub.status.busy": "2023-12-18T15:13:10.224652Z",
     "iopub.status.idle": "2023-12-18T15:13:10.248503Z",
     "shell.execute_reply": "2023-12-18T15:13:10.247720Z",
     "shell.execute_reply.started": "2023-12-18T15:13:10.224871Z"
    }
   },
   "outputs": [],
   "source": [
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels,\n",
    "                 batch_size, is_train=False,\n",
    "                 mix=False, augment=False):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "        self.is_augment = augment\n",
    "        if(self.is_train):\n",
    "            self.on_epoch_end()\n",
    "        self.is_mix = mix\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        if(self.is_train):\n",
    "            return self.train_generate(batch_x, batch_y)\n",
    "        return self.valid_generate(batch_x, batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if(self.is_train):\n",
    "            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n",
    "    \n",
    "    def mix_up(self, x, y):\n",
    "        lam = np.random.beta(0.2, 0.4)\n",
    "        ori_index = np.arange(int(len(x)))\n",
    "        index_array = np.arange(int(len(x)))\n",
    "        np.random.shuffle(index_array)        \n",
    "        \n",
    "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
    "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
    "        \n",
    "        return mixed_x, mixed_y\n",
    "\n",
    "    def train_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            img = cv2.imread('/kaggle/input/neu-grading4/train/'+str(sample)+'.jpg')\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            if(self.is_augment):\n",
    "                img = seq.augment_image(img)\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        if(self.is_mix):\n",
    "            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n",
    "        return batch_images, batch_y\n",
    "\n",
    "    def valid_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            img = cv2.imread('/kaggle/input/neu-grading4/train/'+str(sample)+'.jpg')\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        return batch_images, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:10.250084Z",
     "iopub.status.busy": "2023-12-18T15:13:10.249832Z",
     "iopub.status.idle": "2023-12-18T15:13:10.262622Z",
     "shell.execute_reply": "2023-12-18T15:13:10.261691Z",
     "shell.execute_reply.started": "2023-12-18T15:13:10.250042Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:10.264390Z",
     "iopub.status.busy": "2023-12-18T15:13:10.263998Z",
     "iopub.status.idle": "2023-12-18T15:13:10.273152Z",
     "shell.execute_reply": "2023-12-18T15:13:10.272083Z",
     "shell.execute_reply.started": "2023-12-18T15:13:10.264271Z"
    }
   },
   "outputs": [],
   "source": [
    "function = \"softmax\"\n",
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = ResNet50(include_top=False,\n",
    "                   weights=None,\n",
    "                   input_tensor=input_tensor)\n",
    "    base_model.load_weights('../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_output = Dense(n_out, activation=function, name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:10.274673Z",
     "iopub.status.busy": "2023-12-18T15:13:10.274415Z",
     "iopub.status.idle": "2023-12-18T15:13:24.014788Z",
     "shell.execute_reply": "2023-12-18T15:13:24.013919Z",
     "shell.execute_reply.started": "2023-12-18T15:13:10.274620Z"
    }
   },
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "\n",
    "epochs = 150; batch_size = 32\n",
    "checkpoint = ModelCheckpoint('../working/Resnet50.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
    "                                   verbose=1, mode='min', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=9)\n",
    "\n",
    "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "# callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early]\n",
    "\n",
    "train_generator = My_Generator(train_x, train_y, 128, is_train=True)\n",
    "train_mixup = My_Generator(train_x, train_y, batch_size, is_train=True, mix=False, augment=True)\n",
    "valid_generator = My_Generator(valid_x, valid_y, batch_size, is_train=False)\n",
    "\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:24.016359Z",
     "iopub.status.busy": "2023-12-18T15:13:24.016083Z",
     "iopub.status.idle": "2023-12-18T15:13:24.037585Z",
     "shell.execute_reply": "2023-12-18T15:13:24.036585Z",
     "shell.execute_reply.started": "2023-12-18T15:13:24.016308Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class QWKEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), batch_size=64, interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.batch_size = batch_size\n",
    "        self.valid_generator, self.y_val = validation_data\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict_generator(generator=self.valid_generator,\n",
    "                                                  steps=np.ceil(float(len(self.y_val)) / float(self.batch_size)),\n",
    "                                                  workers=1, use_multiprocessing=True,\n",
    "                                                  verbose=1)\n",
    "            def flatten(y):\n",
    "                return np.argmax(y, axis=1).reshape(-1)\n",
    "                # return np.sum(y.astype(int), axis=1) - 1\n",
    "            \n",
    "            score = cohen_kappa_score(flatten(self.y_val),\n",
    "                                      flatten(y_pred),\n",
    "                                      labels=[0,1,2,3,4],\n",
    "                                      weights='quadratic')\n",
    "#             print(flatten(self.y_val)[:5])\n",
    "#             print(flatten(y_pred)[:5])\n",
    "            print(\"\\n epoch: %d - QWK_score: %.6f \\n\" % (epoch+1, score))\n",
    "            self.history.append(score)\n",
    "            if score >= max(self.history):\n",
    "                print('save checkpoint: ', score)\n",
    "                self.model.save('../working/Resnet50_bestqwk.h5')\n",
    "\n",
    "qwk = QWKEvaluation(validation_data=(valid_generator, valid_y),\n",
    "                    batch_size=batch_size, interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:13:24.039249Z",
     "iopub.status.busy": "2023-12-18T15:13:24.038947Z",
     "iopub.status.idle": "2023-12-18T15:14:17.738552Z",
     "shell.execute_reply": "2023-12-18T15:14:17.733255Z",
     "shell.execute_reply.started": "2023-12-18T15:13:24.039173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7/7 [==============================] - 25s 4s/step - loss: 2.4986\n",
      "5/5 [==============================] - 7s 1s/step\n",
      "\n",
      " epoch: 1 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 6s 926ms/step - loss: 1.3811\n",
      "5/5 [==============================] - 3s 650ms/step\n",
      "\n",
      " epoch: 2 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7aef5da9bbe0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warm up model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-5,0):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    # loss='binary_crossentropy',\n",
    "    optimizer=Adam(1e-3))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_y)) / float(128)),\n",
    "    epochs=2,\n",
    "    workers=WORKERS, use_multiprocessing=True,\n",
    "    verbose=1,\n",
    "    callbacks=[qwk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:14:17.746094Z",
     "iopub.status.busy": "2023-12-18T15:14:17.745711Z",
     "iopub.status.idle": "2023-12-18T15:20:53.083444Z",
     "shell.execute_reply": "2023-12-18T15:20:53.081920Z",
     "shell.execute_reply.started": "2023-12-18T15:14:17.746021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "27/27 [==============================] - 47s 2s/step - loss: 1.2298 - acc: 0.5023 - val_loss: 1.1197 - val_acc: 0.5667\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.11969, saving model to ../working/Resnet50.h5\n",
      "5/5 [==============================] - 5s 918ms/step\n",
      "\n",
      " epoch: 1 - QWK_score: 0.453744 \n",
      "\n",
      "save checkpoint:  0.45374449339207046\n",
      "Epoch 2/150\n",
      "27/27 [==============================] - 21s 784ms/step - loss: 1.0001 - acc: 0.5874 - val_loss: 1.2324 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.11969\n",
      "5/5 [==============================] - 3s 605ms/step\n",
      "\n",
      " epoch: 2 - QWK_score: 0.478603 \n",
      "\n",
      "save checkpoint:  0.47860342963077407\n",
      "Epoch 3/150\n",
      "27/27 [==============================] - 22s 817ms/step - loss: 0.8716 - acc: 0.6552 - val_loss: 1.0347 - val_acc: 0.6267\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.11969 to 1.03473, saving model to ../working/Resnet50.h5\n",
      "5/5 [==============================] - 3s 590ms/step\n",
      "\n",
      " epoch: 3 - QWK_score: 0.630542 \n",
      "\n",
      "save checkpoint:  0.6305418719211823\n",
      "Epoch 4/150\n",
      "27/27 [==============================] - 22s 819ms/step - loss: 0.7938 - acc: 0.6818 - val_loss: 1.1888 - val_acc: 0.6333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.03473\n",
      "5/5 [==============================] - 3s 615ms/step\n",
      "\n",
      " epoch: 4 - QWK_score: 0.612760 \n",
      "\n",
      "Epoch 5/150\n",
      "27/27 [==============================] - 22s 807ms/step - loss: 0.7052 - acc: 0.7079 - val_loss: 0.9468 - val_acc: 0.6267\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.03473 to 0.94675, saving model to ../working/Resnet50.h5\n",
      "5/5 [==============================] - 3s 602ms/step\n",
      "\n",
      " epoch: 5 - QWK_score: 0.665130 \n",
      "\n",
      "save checkpoint:  0.6651303471121993\n",
      "Epoch 6/150\n",
      "27/27 [==============================] - 22s 808ms/step - loss: 0.6451 - acc: 0.7475 - val_loss: 1.2276 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.94675\n",
      "5/5 [==============================] - 3s 618ms/step\n",
      "\n",
      " epoch: 6 - QWK_score: 0.576245 \n",
      "\n",
      "Epoch 7/150\n",
      "27/27 [==============================] - 22s 802ms/step - loss: 0.6084 - acc: 0.7588 - val_loss: 1.0846 - val_acc: 0.6467\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.94675\n",
      "5/5 [==============================] - 3s 610ms/step\n",
      "\n",
      " epoch: 7 - QWK_score: 0.648986 \n",
      "\n",
      "Epoch 8/150\n",
      "27/27 [==============================] - 22s 811ms/step - loss: 0.5137 - acc: 0.8020 - val_loss: 1.1018 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.94675\n",
      "5/5 [==============================] - 3s 599ms/step\n",
      "\n",
      " epoch: 8 - QWK_score: 0.533160 \n",
      "\n",
      "Epoch 9/150\n",
      "27/27 [==============================] - 21s 796ms/step - loss: 0.4665 - acc: 0.8292 - val_loss: 1.2669 - val_acc: 0.6067\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.94675\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "5/5 [==============================] - 3s 589ms/step\n",
      "\n",
      " epoch: 9 - QWK_score: 0.556240 \n",
      "\n",
      "Epoch 10/150\n",
      "27/27 [==============================] - 22s 799ms/step - loss: 0.4294 - acc: 0.8373 - val_loss: 1.1177 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.94675\n",
      "5/5 [==============================] - 3s 591ms/step\n",
      "\n",
      " epoch: 10 - QWK_score: 0.727189 \n",
      "\n",
      "save checkpoint:  0.7271893626776709\n",
      "Epoch 11/150\n",
      "27/27 [==============================] - 22s 801ms/step - loss: 0.3577 - acc: 0.8535 - val_loss: 1.2084 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.94675\n",
      "5/5 [==============================] - 3s 588ms/step\n",
      "\n",
      " epoch: 11 - QWK_score: 0.682125 \n",
      "\n",
      "Epoch 12/150\n",
      "27/27 [==============================] - 22s 802ms/step - loss: 0.3488 - acc: 0.8607 - val_loss: 1.1393 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.94675\n",
      "5/5 [==============================] - 3s 606ms/step\n",
      "\n",
      " epoch: 12 - QWK_score: 0.811335 \n",
      "\n",
      "save checkpoint:  0.8113350507652675\n",
      "Epoch 13/150\n",
      "27/27 [==============================] - 22s 808ms/step - loss: 0.3141 - acc: 0.8923 - val_loss: 1.9141 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.94675\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "5/5 [==============================] - 3s 614ms/step\n",
      "\n",
      " epoch: 13 - QWK_score: 0.673382 \n",
      "\n",
      "Epoch 14/150\n",
      "27/27 [==============================] - 22s 807ms/step - loss: 0.2643 - acc: 0.8990 - val_loss: 1.5434 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.94675\n",
      "5/5 [==============================] - 3s 615ms/step\n",
      "\n",
      " epoch: 14 - QWK_score: 0.681922 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7aef5da53e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early, qwk]\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            # loss=kappa_loss,\n",
    "            # loss='binary_crossentropy',\n",
    "            # optimizer=Adam(lr=1e-4),\n",
    "            optimizer=AdamAccumulate(lr=1e-4, accum_iters=2),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_mixup,\n",
    "    steps_per_epoch=np.ceil(float(len(train_x)) / float(batch_size)),\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_x)) / float(batch_size)),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    workers=1, use_multiprocessing=False,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:20:53.087302Z",
     "iopub.status.busy": "2023-12-18T15:20:53.086592Z",
     "iopub.status.idle": "2023-12-18T15:20:55.568477Z",
     "shell.execute_reply": "2023-12-18T15:20:55.567270Z",
     "shell.execute_reply.started": "2023-12-18T15:20:53.087217Z"
    }
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('/kaggle/input/neu-grading4/sample_submission.csv')\n",
    "# model.load_weights('../working/Resnet50.h5')\n",
    "model.load_weights('../working/Resnet50_bestqwk.h5')\n",
    "predicted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:20:55.570032Z",
     "iopub.status.busy": "2023-12-18T15:20:55.569799Z",
     "iopub.status.idle": "2023-12-18T15:21:07.425694Z",
     "shell.execute_reply": "2023-12-18T15:21:07.424909Z",
     "shell.execute_reply.started": "2023-12-18T15:20:55.569994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [00:10, 27.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, name in tqdm(enumerate(submit['Image'])):\n",
    "    path = os.path.join('/kaggle/input/neu-grading4/test/', str(name)+'.jpg')\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (SIZE, SIZE))\n",
    "    score_predict = model.predict((image[np.newaxis])/255)\n",
    "    label_predict = np.argmax(score_predict)\n",
    "    # label_predict = score_predict.astype(int).sum() - 1\n",
    "    predicted.append(str(label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T15:21:07.427475Z",
     "iopub.status.busy": "2023-12-18T15:21:07.427170Z",
     "iopub.status.idle": "2023-12-18T15:21:07.677454Z",
     "shell.execute_reply": "2023-12-18T15:21:07.676597Z",
     "shell.execute_reply.started": "2023-12-18T15:21:07.427423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Predict</th>\n",
       "      <th>Retinopathy_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image  Predict Retinopathy_grade\n",
       "0      1      NaN                 3\n",
       "1      2      NaN                 0\n",
       "2      3      NaN                 0\n",
       "3      4      NaN                 0\n",
       "4      5      NaN                 0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['Retinopathy_grade'] = predicted\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 875431,
     "sourceId": 14774,
     "sourceType": "competition"
    },
    {
     "datasetId": 6209,
     "sourceId": 9900,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4183448,
     "sourceId": 7226495,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4184038,
     "sourceId": 7230169,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 27938,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
