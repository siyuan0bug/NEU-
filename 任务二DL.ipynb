{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T02:03:56.875598Z",
     "iopub.status.busy": "2024-01-12T02:03:56.874778Z",
     "iopub.status.idle": "2024-01-12T02:04:02.840777Z",
     "shell.execute_reply": "2024-01-12T02:04:02.839926Z",
     "shell.execute_reply.started": "2023-11-16T15:21:05.623132Z"
    },
    "papermill": {
     "duration": 5.981544,
     "end_time": "2024-01-12T02:04:02.841003",
     "exception": false,
     "start_time": "2024-01-12T02:03:56.859459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T02:04:02.893810Z",
     "iopub.status.busy": "2024-01-12T02:04:02.893139Z",
     "iopub.status.idle": "2024-01-12T02:04:02.896025Z",
     "shell.execute_reply": "2024-01-12T02:04:02.895460Z",
     "shell.execute_reply.started": "2023-11-16T15:21:12.090990Z"
    },
    "papermill": {
     "duration": 0.021915,
     "end_time": "2024-01-12T02:04:02.896172",
     "exception": false,
     "start_time": "2024-01-12T02:04:02.874257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_model(width, height):\n",
    "    model_input = tf.keras.layers.Input(shape=(width, height, 3), name='image_input')\n",
    "    model_main = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet')(model_input)\n",
    "    model_dense1 = tf.keras.layers.Flatten()(model_main)\n",
    "    model_dense2 = tf.keras.layers.Dense(128, activation='relu')(model_dense1)\n",
    "    model_out = tf.keras.layers.Dense(12, activation=\"softmax\")(model_dense2)\n",
    "\n",
    "    model = tf.keras.models.Model(model_input,  model_out)\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.00004, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T02:04:02.951341Z",
     "iopub.status.busy": "2024-01-12T02:04:02.950225Z",
     "iopub.status.idle": "2024-01-12T02:04:02.952943Z",
     "shell.execute_reply": "2024-01-12T02:04:02.953458Z",
     "shell.execute_reply.started": "2023-11-16T15:21:12.100358Z"
    },
    "papermill": {
     "duration": 0.024637,
     "end_time": "2024-01-12T02:04:02.953650",
     "exception": false,
     "start_time": "2024-01-12T02:04:02.929013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generators():\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=360,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.5,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.0, # change to use validation instead of training on entire training set\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory='/kaggle/input/plant-seedlings-classification/train',\n",
    "        target_size=(width, height),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode=\"categorical\",\n",
    "        subset='training',\n",
    "    )\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        directory='/kaggle/input/plant-seedlings-classification/train',\n",
    "        target_size=(width, height),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode=\"categorical\",\n",
    "        subset='validation',\n",
    "    )\n",
    "\n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory='/kaggle/input/plant-seedlings-classification/',\n",
    "        classes=['test'],\n",
    "        target_size=(width, height),\n",
    "        batch_size=1,\n",
    "        color_mode='rgb',\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T02:04:03.002792Z",
     "iopub.status.busy": "2024-01-12T02:04:03.002104Z",
     "iopub.status.idle": "2024-01-12T02:04:03.005380Z",
     "shell.execute_reply": "2024-01-12T02:04:03.004736Z",
     "shell.execute_reply.started": "2023-11-16T15:21:12.111239Z"
    },
    "papermill": {
     "duration": 0.018864,
     "end_time": "2024-01-12T02:04:03.005523",
     "exception": false,
     "start_time": "2024-01-12T02:04:02.986659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_callbacks():\n",
    "    save_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='model.h5',\n",
    "        monitor='val_acc',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return save_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T02:04:03.052902Z",
     "iopub.status.busy": "2024-01-12T02:04:03.052227Z",
     "iopub.status.idle": "2024-01-12T02:04:03.055013Z",
     "shell.execute_reply": "2024-01-12T02:04:03.054329Z",
     "shell.execute_reply.started": "2023-11-16T15:21:12.126770Z"
    },
    "papermill": {
     "duration": 0.017545,
     "end_time": "2024-01-12T02:04:03.055145",
     "exception": false,
     "start_time": "2024-01-12T02:04:03.037600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_epoch     = 40\n",
    "batch_size   = 16\n",
    "width        = 299\n",
    "height       = 299\n",
    "species_list = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \"Common wheat\", \"Fat Hen\",\n",
    "                \"Loose Silky-bent\", \"Maize\", \"Scentless Mayweed\", \"Shepherds Purse\", \"Small-flowered Cranesbill\",\n",
    "                \"Sugar beet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T02:04:03.104842Z",
     "iopub.status.busy": "2024-01-12T02:04:03.104185Z",
     "iopub.status.idle": "2024-01-12T03:52:24.163014Z",
     "shell.execute_reply": "2024-01-12T03:52:24.162252Z"
    },
    "papermill": {
     "duration": 6501.07456,
     "end_time": "2024-01-12T03:52:24.163187",
     "exception": false,
     "start_time": "2024-01-12T02:04:03.088627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, None, None, 1536)  54336736  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 98304)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               12583040  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 66,921,324\n",
      "Trainable params: 66,860,780\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n",
      "Found 4440 images belonging to 12 classes.\n",
      "Found 0 images belonging to 12 classes.\n",
      "Found 1104 images belonging to 1 classes.\n",
      "Epoch 1/40\n",
      "277/277 [==============================] - 192s 604ms/step - loss: 1.9937 - accuracy: 0.3351\n",
      "Epoch 2/40\n",
      "277/277 [==============================] - 160s 575ms/step - loss: 0.5424 - accuracy: 0.8194\n",
      "Epoch 3/40\n",
      "277/277 [==============================] - 161s 578ms/step - loss: 0.3796 - accuracy: 0.8723\n",
      "Epoch 4/40\n",
      "277/277 [==============================] - 161s 580ms/step - loss: 0.3119 - accuracy: 0.8877\n",
      "Epoch 5/40\n",
      "277/277 [==============================] - 161s 578ms/step - loss: 0.2429 - accuracy: 0.9137\n",
      "Epoch 6/40\n",
      "277/277 [==============================] - 161s 581ms/step - loss: 0.2188 - accuracy: 0.9216\n",
      "Epoch 7/40\n",
      "277/277 [==============================] - 160s 577ms/step - loss: 0.2084 - accuracy: 0.9252\n",
      "Epoch 8/40\n",
      "277/277 [==============================] - 161s 579ms/step - loss: 0.1813 - accuracy: 0.9411\n",
      "Epoch 9/40\n",
      "277/277 [==============================] - 161s 580ms/step - loss: 0.1637 - accuracy: 0.9404\n",
      "Epoch 10/40\n",
      "277/277 [==============================] - 160s 577ms/step - loss: 0.1601 - accuracy: 0.9487\n",
      "Epoch 11/40\n",
      "277/277 [==============================] - 160s 575ms/step - loss: 0.1363 - accuracy: 0.9514\n",
      "Epoch 12/40\n",
      "277/277 [==============================] - 161s 579ms/step - loss: 0.1566 - accuracy: 0.9441\n",
      "Epoch 13/40\n",
      "277/277 [==============================] - 161s 581ms/step - loss: 0.1200 - accuracy: 0.9604\n",
      "Epoch 14/40\n",
      "277/277 [==============================] - 162s 583ms/step - loss: 0.1365 - accuracy: 0.9521\n",
      "Epoch 15/40\n",
      "277/277 [==============================] - 161s 581ms/step - loss: 0.1201 - accuracy: 0.9636\n",
      "Epoch 16/40\n",
      "277/277 [==============================] - 161s 579ms/step - loss: 0.1088 - accuracy: 0.9642\n",
      "Epoch 17/40\n",
      "277/277 [==============================] - 162s 582ms/step - loss: 0.0971 - accuracy: 0.9651\n",
      "Epoch 18/40\n",
      "277/277 [==============================] - 162s 584ms/step - loss: 0.0889 - accuracy: 0.9694\n",
      "Epoch 19/40\n",
      "277/277 [==============================] - 162s 582ms/step - loss: 0.0922 - accuracy: 0.9665\n",
      "Epoch 20/40\n",
      "277/277 [==============================] - 162s 582ms/step - loss: 0.0965 - accuracy: 0.9653\n",
      "Epoch 21/40\n",
      "277/277 [==============================] - 162s 583ms/step - loss: 0.1049 - accuracy: 0.9666\n",
      "Epoch 22/40\n",
      "277/277 [==============================] - 161s 580ms/step - loss: 0.0891 - accuracy: 0.9702\n",
      "Epoch 23/40\n",
      "277/277 [==============================] - 160s 577ms/step - loss: 0.0984 - accuracy: 0.9681\n",
      "Epoch 24/40\n",
      "277/277 [==============================] - 162s 582ms/step - loss: 0.1018 - accuracy: 0.9696\n",
      "Epoch 25/40\n",
      "277/277 [==============================] - 162s 584ms/step - loss: 0.0844 - accuracy: 0.9721\n",
      "Epoch 26/40\n",
      "277/277 [==============================] - 161s 579ms/step - loss: 0.0719 - accuracy: 0.9774\n",
      "Epoch 27/40\n",
      "277/277 [==============================] - 161s 581ms/step - loss: 0.0768 - accuracy: 0.9753\n",
      "Epoch 28/40\n",
      "277/277 [==============================] - 162s 584ms/step - loss: 0.0728 - accuracy: 0.9752\n",
      "Epoch 29/40\n",
      "277/277 [==============================] - 162s 582ms/step - loss: 0.0834 - accuracy: 0.9724\n",
      "Epoch 30/40\n",
      "277/277 [==============================] - 161s 581ms/step - loss: 0.0724 - accuracy: 0.9765\n",
      "Epoch 31/40\n",
      "277/277 [==============================] - 162s 583ms/step - loss: 0.0698 - accuracy: 0.9735\n",
      "Epoch 32/40\n",
      "277/277 [==============================] - 162s 582ms/step - loss: 0.0577 - accuracy: 0.9802\n",
      "Epoch 33/40\n",
      "277/277 [==============================] - 162s 582ms/step - loss: 0.0660 - accuracy: 0.9794\n",
      "Epoch 34/40\n",
      "277/277 [==============================] - 162s 584ms/step - loss: 0.0684 - accuracy: 0.9779\n",
      "Epoch 35/40\n",
      "277/277 [==============================] - 163s 586ms/step - loss: 0.0849 - accuracy: 0.9750\n",
      "Epoch 36/40\n",
      "277/277 [==============================] - 162s 583ms/step - loss: 0.0636 - accuracy: 0.9785\n",
      "Epoch 37/40\n",
      "277/277 [==============================] - 163s 585ms/step - loss: 0.0507 - accuracy: 0.9841\n",
      "Epoch 38/40\n",
      "277/277 [==============================] - 162s 585ms/step - loss: 0.0553 - accuracy: 0.9799\n",
      "Epoch 39/40\n",
      "277/277 [==============================] - 162s 582ms/step - loss: 0.0500 - accuracy: 0.9836\n",
      "Epoch 40/40\n",
      "277/277 [==============================] - 163s 586ms/step - loss: 0.0622 - accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7b940cac5750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = define_model(width, height)\n",
    "model.summary()\n",
    "train_generator, validation_generator, test_generator = define_generators()\n",
    "save_callback = define_callbacks()\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=nb_epoch,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data= validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "#    callbacks=[save_callback] UNCOMMENT THIS LINE TO SAVE BEST VAL_ACC MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-12T03:52:39.986682Z",
     "iopub.status.busy": "2024-01-12T03:52:39.985857Z",
     "iopub.status.idle": "2024-01-12T03:53:18.582006Z",
     "shell.execute_reply": "2024-01-12T03:53:18.582618Z"
    },
    "papermill": {
     "duration": 42.528032,
     "end_time": "2024-01-12T03:53:18.582834",
     "exception": false,
     "start_time": "2024-01-12T03:52:36.054802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file generated. All done.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator, steps=test_generator.samples)\n",
    "\n",
    "class_list = []\n",
    "\n",
    "for i in range(0, predictions.shape[0]):\n",
    "  y_class = predictions[i, :].argmax(axis=-1)\n",
    "  class_list += [species_list[y_class]]\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['file'] = test_generator.filenames\n",
    "submission['file'] = submission['file'].str.replace(r'test/', '')\n",
    "submission['species'] = class_list\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print('Submission file generated. All done.')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3964591,
     "sourceId": 6902008,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30068,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6582.228861,
   "end_time": "2024-01-12T03:53:33.218372",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-12T02:03:50.989511",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
